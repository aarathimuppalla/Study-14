{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# OpenML in Python \n",
    "Joaquin Vanschoren @joavanschoren"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## How to...\n",
    "- Download datasets and tasks in Python and Jupyter\n",
    "- Use scikit-learn to build classifiers\n",
    "- Upload the results to the server\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation\n",
    "Via source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#! git clone https://github.com/openml/openml-python.\n",
    "#! cd openml-python\n",
    "#! python setup.py install"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Authentication\n",
    "* Create an OpenML account on http://www.openml.org\n",
    "* Go to your OpenML account, click 'Account Settings', and then 'API authentication'. \n",
    "<center><img src=\"images/openml_login.png\" width=\"800\"></center>\n",
    "* Create a little file to store the API key locally: ~/.openml/config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "apikey=FILL_IN_API_KEY\n",
    "cachedir=FILL_IN_CACHE_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Alternative authentication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import openml\n",
    "\n",
    "# assumes you have your api key in ~/.openml/config\n",
    "# amueller's read/write key that he will throw away later\n",
    "openml.config.apikey='610344db6388d9ba34f6db45a3cf71de'\n",
    "# we also want to use the test server so as not to polute the production system\n",
    "openml.config.server = \"http://www.openml.org/api/v1/xml\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## List ALL the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 10 of 19538 datasets...\n",
      "   did             name  NumberOfInstances  NumberOfFeatures\n",
      "0    1           anneal                898                39\n",
      "1    2           anneal                898                39\n",
      "2    3         kr-vs-kp               3196                37\n",
      "3    4            labor                 57                17\n",
      "4    5       arrhythmia                452               280\n",
      "5    6           letter              20000                17\n",
      "6    7        audiology                226                70\n",
      "7    8  liver-disorders                345                 7\n",
      "8    9            autos                205                26\n",
      "9   10            lymph                148                19\n"
     ]
    }
   ],
   "source": [
    "from openml import datasets, tasks, runs\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "datalist = datasets.list_datasets()\n",
    "\n",
    "data = pd.DataFrame(datalist)\n",
    "print(\"First 10 of %s datasets...\" % len(datalist))\n",
    "print(data[:10][['did','name','NumberOfInstances','NumberOfFeatures']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Subset based on any property"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 10 of 605 datasets...\n",
      "    did            name  NumberOfInstances  NumberOfFeatures\n",
      "2     3        kr-vs-kp               3196                37\n",
      "3     4           labor                 57                17\n",
      "12   13   breast-cancer                286                10\n",
      "14   15        breast-w                699                10\n",
      "23   24        mushroom               8124                23\n",
      "24   25           colic                368                28\n",
      "26   27           colic                368                23\n",
      "28   29        credit-a                690                16\n",
      "30   31        credit-g               1000                21\n",
      "32   33  cylinder-bands                540                40\n"
     ]
    }
   ],
   "source": [
    "bin_data = data.loc[data['NumberOfClasses'] == 2]\n",
    "print(\"First 10 of %s datasets...\" % len(bin_data))\n",
    "print(bin_data[:10][['did','name', 'NumberOfInstances','NumberOfFeatures']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Subset based on any property"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 10 of 605 datasets...\n",
      "         did                          name  NumberOfInstances\n",
      "1305    1588                           w8a              64700\n",
      "2424    4533  KEGGMetabolicReactionNetwork              65554\n",
      "1308    1591                     connect-4              67557\n",
      "423      554                     mnist_784              70000\n",
      "1296    1578                      real-sim              72309\n",
      "1062    1213                       BNG(mv)              78732\n",
      "19509  23396               COMET_MC_SAMPLE              89640\n",
      "19508  23395               COMET_MC_SAMPLE              89640\n",
      "19537  23512                         higgs              98050\n",
      "2423    4532                         higgs              98050\n"
     ]
    }
   ],
   "source": [
    "big_data = data.loc[data['NumberOfInstances'] > 60000]\n",
    "big_data = big_data.sort_values(by='NumberOfInstances', ascending=True)\n",
    "print(\"First 10 of %s datasets...\" % len(bin_data))\n",
    "print(big_data[:10][['did','name', 'NumberOfInstances']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Download a specific dataset. This is done based on the dataset ID (called 'did' in the table above)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is dataset 'higgs', the target feature is called 'class'\n",
      "URL: http://www.openml.org/data/download/2063675/phpZLgL9q\n",
      "**Author**: Daniel Whiteson daniel'@'uci.edu\", Assistant Professor, Physics, Univ. of California Irvine  \n",
      "**Source**: [UCI](https://archive.ics.uci.edu/ml/datasets/HIGGS)  \n",
      "**Please cite**: Baldi, P., P. Sadowski, and D. Whiteson. Searching for Exotic Particles in High-energy Physics with Deep Learning. Nature Communications 5 (July 2, 2014).  \n",
      "\n",
      "**Note: This is the UCI Higgs dataset, same as version 1, but it fixes the definition of the class attribute, which is categorical, not numeric.**\n",
      "\n",
      "Data\n"
     ]
    }
   ],
   "source": [
    "dataset = openml.datasets.get_dataset(23512)\n",
    "\n",
    "print(\"This is dataset '%s', the target feature is called '%s'\" % (dataset.name, dataset.default_target_attribute))\n",
    "print(\"URL: %s\" % dataset.url)\n",
    "print(dataset.description[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'citation': None,\n",
      " 'collection_date': None,\n",
      " 'contributor': None,\n",
      " 'creator': None,\n",
      " 'data_file': '/Users/joa/.openml/cache/datasets/23512/dataset.arff',\n",
      " 'data_pickle_file': '/Users/joa/.openml/cache/datasets/23512/dataset.pkl',\n",
      " 'default_target_attribute': 'class',\n",
      " 'description': '**Author**: Daniel Whiteson daniel\\'@\\'uci.edu\", Assistant '\n",
      "                'Professor, Physics, Univ. of California Irvine  \\n'\n",
      "                '**Source**: '\n",
      "                '[UCI](https://archive.ics.uci.edu/ml/datasets/HIGGS)  \\n'\n",
      "                '**Please cite**: Baldi, P., P. Sadowski, and D. Whiteson. '\n",
      "                'Searching for Exotic Particles in High-energy Physics with '\n",
      "                'Deep Learning. Nature Communications 5 (July 2, 2014).  \\n'\n",
      "                '\\n'\n",
      "                '**Note: This is the UCI Higgs dataset, same as version 1, but '\n",
      "                'it fixes the definition of the class attribute, which is '\n",
      "                'categorical, not numeric.**\\n'\n",
      "                '\\n'\n",
      "                'Data Set Information:\\n'\n",
      "                '\\n'\n",
      "                'The data has been produced using Monte Carlo simulations. The '\n",
      "                'first 21 features (columns 2-22) are kinematic properties '\n",
      "                'measured by the particle detectors in the accelerator. The '\n",
      "                'last seven features are functions of the first 21 features; '\n",
      "                'these are high-level features derived by physicists to help '\n",
      "                'discriminate between the two classes. There is an interest in '\n",
      "                'using deep learning methods to obviate the need for '\n",
      "                'physicists to manually develop such features. Benchmark '\n",
      "                'results using Bayesian Decision Trees from a standard physics '\n",
      "                'package and 5-layer neural networks are presented in the '\n",
      "                'original paper. The last 500,000 examples are used as a test '\n",
      "                'set.\\n'\n",
      "                '\\n'\n",
      "                '\\n'\n",
      "                'Attribute Information:\\n'\n",
      "                '\\n'\n",
      "                'The first column is the class label (1 for signal, 0 for '\n",
      "                'background), followed by the 28 features (21 low-level '\n",
      "                'features then 7 high-level features): lepton pT, lepton eta, '\n",
      "                'lepton phi, missing energy magnitude, missing energy phi, jet '\n",
      "                '1 pt, jet 1 eta, jet 1 phi, jet 1 b-tag, jet 2 pt, jet 2 eta, '\n",
      "                'jet 2 phi, jet 2 b-tag, jet 3 pt, jet 3 eta, jet 3 phi, jet 3 '\n",
      "                'b-tag, jet 4 pt, jet 4 eta, jet 4 phi, jet 4 b-tag, m_jj, '\n",
      "                'm_jjj, m_lv, m_jlv, m_bb, m_wbb, m_wwbb. For more detailed '\n",
      "                'information about each feature see the original paper.\\n'\n",
      "                '\\n'\n",
      "                '\\n'\n",
      "                'Relevant Papers:\\n'\n",
      "                '\\n'\n",
      "                'Baldi, P., P. Sadowski, and D. Whiteson. &ldquo;Searching for '\n",
      "                'Exotic Particles in High-energy Physics with Deep Learning. '\n",
      "                'Nature Communications 5 (July 2, 2014).',\n",
      " 'format': 'ARFF',\n",
      " 'id': 23512,\n",
      " 'ignore_attributes': None,\n",
      " 'language': None,\n",
      " 'licence': 'Public',\n",
      " 'md5_cheksum': '1a216f3bb3f6a961b4023179fca78452',\n",
      " 'name': 'higgs',\n",
      " 'original_data_url': None,\n",
      " 'paper_url': None,\n",
      " 'row_id_attribute': None,\n",
      " 'tag': None,\n",
      " 'update_comment': None,\n",
      " 'upload_date': '2016-06-21 15:03:06',\n",
      " 'url': 'http://www.openml.org/data/download/2063675/phpZLgL9q',\n",
      " 'version': 2,\n",
      " 'version_label': None,\n",
      " 'visibility': 'public'}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "pprint(vars(dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Get the actual data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   lepton_pT  lepton_eta  lepton_phi  missing_energy_magnitude  \\\n",
      "0   0.907542    0.329147    0.359412                  1.497970   \n",
      "1   0.798835    1.470639   -1.635975                  0.453773   \n",
      "2   1.344385   -0.876626    0.935913                  1.992050   \n",
      "3   1.105009    0.321356    1.522401                  0.882808   \n",
      "4   1.595839   -0.607811    0.007075                  1.818450   \n",
      "5   0.409391   -1.884684   -1.027292                  1.672452   \n",
      "6   0.933895    0.629130    0.527535                  0.238033   \n",
      "7   1.405144    0.536603    0.689554                  1.179567   \n",
      "8   1.176566    0.104161    1.397002                  0.479721   \n",
      "9   0.945974    1.111244    1.218337                  0.907639   \n",
      "\n",
      "   missing_energy_phi    jet1pt   jet1eta   jet1phi  jet1b-tag    jet2pt  \\\n",
      "0           -0.313010  1.095531 -0.557525 -1.588230   2.173076  0.812581   \n",
      "1            0.425629  1.104875  1.282322  1.381664   0.000000  0.851737   \n",
      "2            0.882454  1.786066 -1.646778 -0.942383   0.000000  2.423265   \n",
      "3           -1.205349  0.681466 -1.070464 -0.921871   0.000000  0.800872   \n",
      "4           -0.111906  0.847550 -0.566437  1.581239   2.173076  0.755421   \n",
      "5           -1.604598  1.338015  0.055427  0.013466   2.173076  0.509783   \n",
      "6           -0.966569  0.547811 -0.059439 -1.706866   2.173076  0.941003   \n",
      "7           -0.110061  3.202405 -1.526960 -1.576033   0.000000  2.931537   \n",
      "8            0.265513  1.135563  1.534831 -0.253291   0.000000  1.027247   \n",
      "9            0.821537  1.153243 -0.365420 -1.566055   0.000000  0.744719   \n",
      "\n",
      "   ...     jet4phi  jet4b-tag      m_jj     m_jjj      m_lv     m_jlv  \\\n",
      "0  ...   -0.000819   0.000000  0.302220  0.833048  0.985700  0.978098   \n",
      "1  ...    0.900461   0.000000  0.909753  1.108330  0.985692  0.951331   \n",
      "2  ...   -1.360356   0.000000  0.946652  1.028704  0.998656  0.728281   \n",
      "3  ...    0.113041   0.000000  0.755856  1.361057  0.986610  0.838085   \n",
      "4  ...   -1.274345   3.101961  0.823761  0.938191  0.971758  0.789176   \n",
      "5  ...    1.377130   3.101961  0.869418  1.222083  1.000627  0.545045   \n",
      "6  ...   -1.467454   0.000000  0.901837  1.083671  0.979696  0.783300   \n",
      "7  ...    1.163489   0.000000  1.667071  4.039273  1.175828  1.045352   \n",
      "8  ...    0.530334   0.000000  0.833175  0.773968  0.985750  1.103696   \n",
      "9  ...    0.063653   3.101961  0.829024  0.980648  0.994360  0.908248   \n",
      "\n",
      "       m_bb     m_wbb    m_wwbb  class  \n",
      "0  0.779732  0.992356  0.798343      1  \n",
      "1  0.803252  0.865924  0.780118      1  \n",
      "2  0.869200  1.026736  0.957904      0  \n",
      "3  1.133295  0.872245  0.808487      1  \n",
      "4  0.430553  0.961357  0.957818      0  \n",
      "5  0.698653  0.977314  0.828786      1  \n",
      "6  0.849195  0.894356  0.774879      1  \n",
      "7  1.542972  3.534827  2.740754      1  \n",
      "8  0.849140  0.937104  0.812364      1  \n",
      "9  0.775879  0.783311  0.725122      1  \n",
      "\n",
      "[10 rows x 29 columns]\n"
     ]
    }
   ],
   "source": [
    "X, y, attribute_names = dataset.get_data(target=dataset.default_target_attribute, return_attribute_names=True)\n",
    "iris = pd.DataFrame(X, columns=attribute_names)\n",
    "iris['class'] = y\n",
    "print(iris[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Train a scikit-learn model on the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import preprocessing, ensemble\n",
    "\n",
    "dataset = datasets.get_dataset(61)\n",
    "X, y = dataset.get_data(target=dataset.default_target_attribute)\n",
    "clf = ensemble.RandomForestClassifier()\n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "You can also ask which features are categorical to do your own encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y, categorical = dataset.get_data(target=dataset.default_target_attribute,return_categorical_indicator=True)\n",
    "enc = preprocessing.OneHotEncoder(categorical_features=categorical)\n",
    "X = enc.fit_transform(X)\n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run benchmarks consistently (also across studies and tools), OpenML offers Tasks, which include specific train-test splits and other information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## List ALL the tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 of 46562 tasks:\n",
      "   tid  did        name                  task_type     estimation_procedure\n",
      "0    1    1      anneal  Supervised Classification  10-fold Crossvalidation\n",
      "1    2    2      anneal  Supervised Classification  10-fold Crossvalidation\n",
      "2    3    3    kr-vs-kp  Supervised Classification  10-fold Crossvalidation\n",
      "3    4    4       labor  Supervised Classification  10-fold Crossvalidation\n",
      "4    5    5  arrhythmia  Supervised Classification  10-fold Crossvalidation\n"
     ]
    }
   ],
   "source": [
    "task_list = tasks.list_tasks()\n",
    "\n",
    "tasks = pd.DataFrame(task_list)\n",
    "print(\"First 5 of %s tasks:\" % len(tasks))\n",
    "print(tasks[:5][['tid','did','name','task_type','estimation_procedure']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Download tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenMLTask instance.\n",
      "Task ID: 10\n",
      "Task type: Supervised Classification\n",
      "Dataset id: 10\n"
     ]
    }
   ],
   "source": [
    "task = tasks.get_task(10)\n",
    "print(task)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Runs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Run a scikit-learn classifier on the task (using the right splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2823\n",
      "RandomForest has run on the task.\n"
     ]
    }
   ],
   "source": [
    "from openml.runs import run_task\n",
    "\n",
    "clf = ensemble.RandomForestClassifier()\n",
    "run = run_task(task, clf)\n",
    "print(\"RandomForest has run on the task.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Upload the run to the OpenML server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded run with id 538241\n",
      "Check it at www.openml.org/r/538241\n"
     ]
    }
   ],
   "source": [
    "import xmltodict\n",
    "\n",
    "return_code, response = run.publish()\n",
    "\n",
    "if(return_code == 200):\n",
    "    response_dict = xmltodict.parse(response)\n",
    "    run_id = response_dict['oml:upload_run']['oml:run_id']\n",
    "    print(\"Uploaded run with id %s\" % (run_id))\n",
    "    print(\"Check it at www.openml.org/r/%s\" % (run_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## TL;DR;\n",
    "You can easily run and share scikit-learn experiments on OpenML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4074\n",
      "Uploaded run with id 595118. Check it at www.openml.org/r/595118\n"
     ]
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "from openml import tasks,runs\n",
    "task = tasks.get_task(14951)\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "run = runs.run_task(task, clf)\n",
    "return_code, response = run.publish()\n",
    "\n",
    "# get the run id for reference\n",
    "import xmltodict\n",
    "if(return_code == 200):\n",
    "    response_dict = xmltodict.parse(response)\n",
    "    run_id = response_dict['oml:upload_run']['oml:run_id']\n",
    "    print(\"Uploaded run with id %s. Check it at www.openml.org/r/%s\" % (run_id,run_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Challenge: Build the 'best' model on the Higgs dataset together\n",
    "* Check progress on: http://www.openml.org/t/52950"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from openml import tasks,runs\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import Imputer\n",
    "task = tasks.get_task(52950)\n",
    "estimator = Pipeline([(\"imputer\", Imputer(missing_values=0,\n",
    "                                          strategy=\"mean\",\n",
    "                                          axis=0)),\n",
    "                      (\"knn\", KNeighborsClassifier())])\n",
    "run = runs.run_task(task, estimator)\n",
    "return_code, response = run.publish()\n",
    "\n",
    "# get the run id for reference\n",
    "import xmltodict\n",
    "if(return_code == 200):\n",
    "    response_dict = xmltodict.parse(response)\n",
    "    run_id = response_dict['oml:upload_run']['oml:run_id']\n",
    "    print(\"Uploaded run with id %s. Check it at www.openml.org/r/%s\" % (run_id,run_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "colabVersion": "0.1",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
